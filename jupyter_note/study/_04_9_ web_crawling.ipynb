{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d815cca3-251e-490c-8ee4-5e84d0002b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.7\n",
      "Requirement already satisfied: Requests in c:\\anaconda\\conda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\conda3\\lib\\site-packages (from Requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\conda3\\lib\\site-packages (from Requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\conda3\\lib\\site-packages (from Requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\conda3\\lib\\site-packages (from Requests) (2024.8.30)\n",
      "Requirement already satisfied: BeautifulSoup4 in c:\\anaconda\\conda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\anaconda\\conda3\\lib\\site-packages (from BeautifulSoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "# 서울 시청 웹 크롤링 하기\n",
    "#가상환경 작동 되는지 체크\n",
    "!python --version\n",
    "\n",
    "#정적 크롤링 = BeautifulSoup 사용, 동적 =  selenium\n",
    "#주소 url 가져오는거 = requests\n",
    "!pip install Requests\n",
    "!pip install BeautifulSoup4 #BeautifulSoup4 말고 그냥 BeautifulSoup 깔려 했지만 파이썬 버전이 너무 높아서 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fe4bca8-693f-486f-b7e0-458bc4621b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습 서울 시청 웹 크롤링 하기\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "# as = 별칭 같은걸로, 리퀘스트 일일이 치기 넘 기니까 별칭으로 하려고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588614a8-433a-4b4e-834b-f7c966364ce9",
   "metadata": {},
   "source": [
    "## find 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8500dafb-c6dc-4a6c-a5a1-da3ec02de751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " first_ul \n",
      "\n",
      "<ul class=\"industry\">\n",
      "<li>인공지능</li>\n",
      "<li>빅데이터</li>\n",
      "<li>스마트팩토리</li>\n",
      "</ul>\n",
      "\n",
      "인공지능\n",
      "빅데이터\n",
      "스마트팩토리\n",
      "\n",
      "\n",
      " all_li \n",
      "\n",
      "[<li>인공지능</li>, <li>빅데이터</li>, <li>스마트팩토리</li>]\n",
      "<li>빅데이터</li>\n",
      "빅데이터\n",
      "\n",
      " class \n",
      "\n",
      "<ul class=\"comlang\">\n",
      "<li>Python</li>\n",
      "<li>C++</li>\n",
      "<li>Javascript</li>\n",
      "</ul>\n",
      "\n",
      "Python\n",
      "C++\n",
      "Javascript\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. HTML 문자열 정의\n",
    "html_str = '''\n",
    "<html>\n",
    "  <body>\n",
    "    <div id=\"content\">\n",
    "      <ul class=\"industry\">\n",
    "        <li>인공지능</li>\n",
    "        <li>빅데이터</li>\n",
    "        <li>스마트팩토리</li>\n",
    "      </ul>\n",
    "      <ul class=\"comlang\">\n",
    "        <li>Python</li>\n",
    "        <li>C++</li>\n",
    "        <li>Javascript</li>\n",
    "      </ul>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "# 2. BeautifulSoup 객체 생성\n",
    "soup = bs(html_str, \"html.parser\") # 파싱 = html 소스코드 해석 = 우리가 보기 편하게 바꿔주는거\n",
    "\n",
    "# 3.처음 나오는 <ul> 태크로 추출\n",
    "print('\\n first_ul \\n')\n",
    "first_ul = soup.find('ul')  #find는 처음 나오는 1개만 가져옴 따라서 print(type(first_ul)) 하면 bs4.element.Tag 로 나옴\n",
    "print(first_ul)             # 이건 태그랑 태그 안에 값을 다 가져온다\n",
    "print(first_ul.text)        # 이건 태그를 지워 안에있는 값만 볼수있게 해준다\n",
    "\n",
    "\n",
    "# 4. 모든 요소를 li 태그로 찾기\n",
    "print('\\n all_li \\n')\n",
    "first_all_li = first_ul.findAll('li') # soup.find_All(태그) 형태가 좀 다른데? find_All(태그)랑 findAll(태그)랑 같은건가?\n",
    "print(first_all_li)\n",
    "print(first_all_li[1])\n",
    "print(first_all_li[1].text)\n",
    "# first_all_li.text 이건 안된다. 왜? find all 을 하게 되면 오브잭트(리스트)로 가져오게 되는데 text는 오브잭트에 적용가능한 메서드가 아니다.\n",
    "\n",
    "#만일 위처럼 하려고 한것이 [인공지능, 빅데이터, 스마트 팩토리] 라면\n",
    "# temp = []                     # 임의의 빈 리스트를 만들고 \n",
    "#for i in first_all_li          #for 문을 사용하여 하나하나 .text를 사용하여 append해줘야 한다 \n",
    "    # temp.append(i.text) \n",
    "#또는 [i.text for i in first__all_li] 이렇게 해야한다\n",
    "\n",
    "#5.class 선택자로 찾기\n",
    "print('\\n class \\n')\n",
    "# second_ul = soup.find('ul', attrs={'class' : 'comlang'})\n",
    "second_ul = soup.find('ul', class_='comlang') #위랑 같은것이지만 다르게 표현한 것\n",
    "print(second_ul)\n",
    "print(second_ul.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2889f99e-9d4a-4f87-92e6-177b9b5ed788",
   "metadata": {},
   "source": [
    "## select 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8930bed-4cf3-43b0-989c-7ffb4642fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) select_one(태그이름.클래스) -> 첫 번째 매칭 요소 1개 반환\n",
    "first_ul = soup.select_one('ul.industry')\n",
    "print(first_ul)          # <ul class=\"industry\">…</ul> 전체 태그 출력\n",
    "print(first_ul.text)     # 내부 텍스트만 (공백 포함) 출력\n",
    "\n",
    "# 2) select(셀렉터) -> 매칭되는 모든 요소 리스트로 반환\n",
    "# 여기서는 industry 클래스의 <ul> 내부에서 직접 자식 <li>들을 뽑아냄\n",
    "\n",
    "first_all_li = first_ul.select('ul.industry > li')\n",
    "print(first_all_li)          # [<li>인공지능</li>, <li>빅데이터</li>, …]\n",
    "print(first_all_li[1])       # 두 번째 <li> 요소: <li>빅데이터</li>\n",
    "print(first_all_li[1].text)  # 해당 요소의 텍스트: 빅데이터\n",
    "\n",
    "# 3) 다른 클래스(comlang)도 동일하게\n",
    "second_ul = soup.select_one('ul.comlang')\n",
    "print(second_ul)         # <ul class=\"comlang\">…</ul>\n",
    "print(second_ul.text)    # 내부 텍스트: PythonC++Javascript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f377ad38-33c7-406a-a015-029eec17ceb2",
   "metadata": {},
   "source": [
    "## 서울 시청 웹 크롤링 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f69b0907-3a3c-47dd-a428-3e9b1569b09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li class=\"public\">\n",
      "<a href=\"//yeyak.seoul.go.kr\" onclick=\"action_logging({tr_code:'service01'});\" target=\"_blank\" title=\"새창열림\"><i class=\"ico_service\"></i>공공서비스예약</a>\n",
      "</li>\n",
      "\n",
      "공공서비스예약\n",
      "\n",
      "\n",
      "응답소(민원신고)\n",
      "\n",
      "\n",
      "서울일자리\n",
      "\n",
      "\n",
      "부동산정보\n",
      "\n",
      "\n",
      "서울런\n",
      "\n",
      "\n",
      "서울복지포털\n",
      "\n",
      "\n",
      "서울주거포털\n",
      "\n",
      "\n",
      "청년몽땅정보통\n",
      "\n",
      "\n",
      "내 손안에 서울\n",
      "\n",
      "\n",
      "상상대로 서울\n",
      "\n",
      "\n",
      "평생학습포털\n",
      "\n",
      "\n",
      "시의회\n",
      "\n",
      "\n",
      "응답소(민원신고)\n",
      "\n",
      "\n",
      "시의회\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.seoul.go.kr/main/index.jsp\"\n",
    "web = rq.get(url)\n",
    "html = bs(web.text, 'html.parser')\n",
    "# print(html) # 잘 나오나 체크\n",
    "\n",
    "html.select('a')\n",
    "first_li = html.select_one('li.public')\n",
    "print(first_li)\n",
    "\n",
    "lis = html.select('div.m_service > ul > li')\n",
    "#여기서 복습 ul : 순서 없는 목록 (unordered list) , ol : 순서있는 목록 (ordered list) \n",
    "\n",
    "for li in lis:\n",
    "    print(li.text)\n",
    "\n",
    "print(lis[1].text)\n",
    "print(lis[-1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3de9e5-5bfa-44d5-9cd2-d45f93026878",
   "metadata": {},
   "source": [
    "### 실습 1 국립 중앙박불관 관람 정보\n",
    "\n",
    "1) 국립중앙박물관 사이트에 접속한다.\n",
    "2) robots.txt를 확인한다.\n",
    "3) 관람시간과 관람료를 크롤링한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aee595de-79e2-44cd-b061-c1e7cc161e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 관람료\n",
      "무료 특별전시는 유료\n"
     ]
    }
   ],
   "source": [
    "#국립 중앙박물관 사이트 접속\n",
    "\n",
    "url_museum = 'https://www.museum.go.kr/MUSEUM/main/index.do'\n",
    "museum = rq.get(url_museum)\n",
    "html_m = bs(museum.text, 'html.parser')\n",
    "\n",
    "# 2) robots.txt를 확인한다.\n",
    "# robots.txt = '''\n",
    "# User-agent: *  모든 검색 엔진 봇(크롤러)을 대상으로 적용\n",
    "# Disallow: /    사이트의 모든 경로(“/” 이하 전체)를 크롤링 금지\n",
    "# Allow: /$      확히 루트 URL(/)만 예외적으로 허용\n",
    "\n",
    "# 여기서 /$ 는 “문자열 끝에 /가 있는 URL”을 의미하는 정규표현식 형태\n",
    "\n",
    "# 즉 https://www.museum.go.kr/는 허용 https://www.museum.go.kr/about, https://www.museum.go.kr/index.html 등은 금지\n",
    "\n",
    "# 이렇게 하면 검색 엔진은 홈페이지 내용만 색인할 수 있고, 다른 모든 페이지는 크롤링하지 않아야한다.\n",
    "# '''\n",
    "\n",
    "#관람시간과 관람료는 딱 홈페이지에만 있으니 시작해도 된다.\n",
    "\n",
    "#3. 관람시간과 관람료 크롤링\n",
    "\n",
    "#관람 시간\n",
    "view_time = html_m.select_one('li.info > div')\n",
    "view_time.text #여기서 개행문자만 없애도 되고, 3개로 나눠도 되고\n",
    "\n",
    "#관람료\n",
    "pay_info = html_m.select_one('li.admission > strong').text\n",
    "view_pay = html_m.select_one('li.admission > div > ul > li').text\n",
    "# print(pay_info)\n",
    "# print(view_pay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed715e2-6227-4352-8826-1b221fa5377e",
   "metadata": {},
   "source": [
    "### kbs 뉴스 기사 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66284127-2140-4a0c-8c2f-009f9a9cef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목 :  ‘전방위 압박’ 예고한 미국…우리 협상 전략은?\n",
      "게시일 : 입력 2025.04.20 (21:14)\n",
      "[<br/>, <br/>, <br/>]\n"
     ]
    }
   ],
   "source": [
    "kbs_url = 'https://news.kbs.co.kr/news/pc/view/view.do?ncd=8232558'\n",
    "news = rq.get(kbs_url)\n",
    "html_n = bs(news.text, 'html.parser')\n",
    "\n",
    "# 기사 제목\n",
    "title = html_n.select_one('h4.headline-title').text\n",
    "\n",
    "#기사 게시일 \n",
    "day_date = html_n.select_one('em.input-date').text\n",
    "\n",
    "#본문 내용\n",
    "news_text = html_n.select('div.report-text')\n",
    "\n",
    "print(\"제목 : \",title)\n",
    "print(\"게시일 :\",day_date)\n",
    "print(news_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51cda44-4b54-4cbf-b4ca-7c534cd9b91e",
   "metadata": {},
   "source": [
    "### 명언 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3b4711-a87f-48b8-afb1-e695629116f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"text\" itemprop=\"text\">“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”</span>, <span class=\"text\" itemprop=\"text\">“It is our choices, Harry, that show what we truly are, far more than our abilities.”</span>, <span class=\"text\" itemprop=\"text\">“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”</span>, <span class=\"text\" itemprop=\"text\">“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”</span>, <span class=\"text\" itemprop=\"text\">“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”</span>, <span class=\"text\" itemprop=\"text\">“Try not to become a man of success. Rather become a man of value.”</span>, <span class=\"text\" itemprop=\"text\">“It is better to be hated for what you are than to be loved for what you are not.”</span>, <span class=\"text\" itemprop=\"text\">“I have not failed. I've just found 10,000 ways that won't work.”</span>, <span class=\"text\" itemprop=\"text\">“A woman is like a tea bag; you never know how strong it is until it's in hot water.”</span>, <span class=\"text\" itemprop=\"text\">“A day without sunshine is like, you know, night.”</span>]\n"
     ]
    }
   ],
   "source": [
    "q_url = \"https://quotes.toscrape.com/\"\n",
    "res = rq.get(q_url)\n",
    "soup = bs(res.text, \"html.parser\")\n",
    "\n",
    "quo = soup.select(\"div.quote > span.text\")\n",
    "print(quo) 체크\n",
    "\n",
    "quotes_b = [span.text for span in soup.select(\"div.quote > span.text\")]\n",
    "\n",
    "# 작가\n",
    "authors_b = [small.text for small in soup.select(\"div.quote > span > small.author\")]\n",
    "\n",
    "print(\"명언:\", quotes_b)\n",
    "print(\"작가:\", authors_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6865a57e-02cb-4ea2-bc68-a2f12339c7eb",
   "metadata": {},
   "source": [
    "### 실습 3 환율 정보 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "429155d7-0695-4ddf-a316-9631039e2b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[[], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "ex_url = 'https://finance.naver.com/marketindex/'\n",
    "res = rq.get(ex_url)\n",
    "soup = bs(res.text, \"html.parser\")\n",
    "\n",
    "name = []\n",
    "\n",
    "# for n in range(5):\n",
    "#     name.append(soup.select('tr:nth-child(n) > td.tit > a'))\n",
    "\n",
    "print(soup.select('table > tbody > tr:nth-child(1) > td.tit > a'))\n",
    "\n",
    "name.append(soup.select('tr:nth-child(1) > td.tit > a'))\n",
    "name.append(soup.select('tr:nth-child(2) > td.tit > a'))\n",
    "name.append(soup.select('tr:nth-child(3) > td.tit > a'))\n",
    "name.append(soup.select('tr:nth-child(4) > td.tit > a'))\n",
    "\n",
    "print(name)\n",
    "    \n",
    "# nation = \n",
    "# print(nation)\n",
    "\n",
    "# list_n =[]\n",
    "\n",
    "# for n in nation:\n",
    "#     list_n.append(n)\n",
    "    \n",
    "# print(list_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e88ce14-4a61-43c5-bcf0-256f619fdd3a",
   "metadata": {},
   "source": [
    "### 실습4 주식정보 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c747b9f-413d-491b-9f15-dbe8624d3707",
   "metadata": {},
   "source": [
    "## find 와 select 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd773c4e-2618-4829-87ee-e536699fce41",
   "metadata": {},
   "source": [
    "find \n",
    "목적은 원하는 태그를 찾는 것이다. \n",
    "태그는 이름(name), 속성(attribute), 속성값(value)로 구성된다. 따라서 find로 이름, 속성, 속성값을 특정하여 태그를 찾을 수 있다.\n",
    "find는 tag를 웹의 구조 안에서 파악하는 것이 목적:syntax\n",
    "\n",
    "\n",
    "select \n",
    "CSS selector로 tag 객체를 찾아 반환하는것. \n",
    "이는 CSS에서 HTML을 태깅하는 방법을 활용한 메소드다. \n",
    "가장 첫 번째 결과를 반환하는 select_one()은 find()에, 전체 결과를 리스트로 반환하는 select()는 find_all()에 대응한다.\n",
    "select는 tag가 갖는 속성을 기준으로 역할에 따라 태그를 정의하는 것:semantics이 목적\n",
    "\n",
    "• Syntax (구문): 언어의 표현식, 문장, 프로그램 단위와 같은 구조적 형태를 말한다. 쉽게 말해 언어가 작성되는 형식을 의미한다.\n",
    "\n",
    "• Semantics (의미): 표현식, 문장, 프로그램 단위가 가지고 있는 의미, 즉 언어의 문장들이 실제로 수행할 동작을 의미한다.\n",
    "\n",
    "\n",
    "따라서 엄격한 규칙에 따른 구조보다 속성과 역할에 따른 관계망으로 웹을 바라보는 Semantics 가 파이썬과 같은 객체 지향 언어가 추구하는 바이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369c8d4-c582-46b8-bbb8-bb65a44ee508",
   "metadata": {},
   "source": [
    "# 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932471ab-09a6-41ac-80be-c7f0c4df560c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
